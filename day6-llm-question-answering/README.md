# ğŸ“˜ Day 6 â€“ LLM Question Answering App (Zero-Shot)

This is part of my **45-Day LLM Mastery Challenge**.  
Today, I built a simple and powerful **LLM-powered Question Answering App** using Hugging Face's transformers.

## ğŸ§  What I Learned
- What is **zero-shot Q&A** using pretrained transformer models
- How to format `context` and `question` for best results
- Basics of QA-specific models like `distilbert-base-cased-distilled-squad`

## ğŸ› ï¸ Tools Used
- Hugging Face Transformers
- Google Colab
- Pretrained model: `distilbert-base-cased-distilled-squad`

## ğŸ” Demo Use Case

**Context:**
> LLMs are trained on vast corpora and can perform translation, summarization, and question answering...

**Question:**
> What are LLMs used for?

**Model Answer:**
> translation, summarization, and question answering

## ğŸ“‚ Files
- `day6_llm_qa_app.ipynb` â†’ Main Google Colab Notebook

## ğŸ”— Run on Colab
[ğŸ‘‰ Open in Google Colab](https://colab.research.google.com/drive/18FDjtKqGrh_orXJCvdIOOcy56JTWl_YY#scrollTo=nsSM1c4xLD5o)

## ğŸŒŸ Next Step
We'll move toward **building retrieval-augmented generation apps** soon!

---

â­ Star this repo if you're following the challenge!  
Connect with me on [LinkedIn](https://www.linkedin.com/in/devrakeshpatel/) for daily updates.

#LLM #QA #Transformers #DeepLearning #HuggingFace #45DayChallenge #NLP
