# ğŸ—£ï¸ Day 4: Prompting + Finetuning

## ğŸ§  What I Learned
- Zero-shot vs Few-shot vs Chain-of-Thought prompting
- Pretraining vs Finetuning vs Instruction Tuning
- Model families: GPT, BERT, T5, LLaMA

## ğŸ”¬ Experimented With
- Prompt variations using GPT2 (Hugging Face)
- Tasks: summarization, translation, reasoning

## ğŸ”§ Tools Used
- Hugging Face Transformers
- Google Colab
