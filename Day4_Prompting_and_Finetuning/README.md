# 🗣️ Day 4: Prompting + Finetuning

## 🧠 What I Learned
- Zero-shot vs Few-shot vs Chain-of-Thought prompting
- Pretraining vs Finetuning vs Instruction Tuning
- Model families: GPT, BERT, T5, LLaMA

## 🔬 Experimented With
- Prompt variations using GPT2 (Hugging Face)
- Tasks: summarization, translation, reasoning

## 🔧 Tools Used
- Hugging Face Transformers
- Google Colab

- ## 🔗 Notebook Link
[🔗 Open Day 4 Notebook in Colab](https://colab.research.google.com/drive/1Np3l4-sU-QfUEiSaL5d-Q1L1eMjRauUU)
