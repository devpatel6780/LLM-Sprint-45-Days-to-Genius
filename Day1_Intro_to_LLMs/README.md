# 📘 Day 1: Introduction to LLMs

## 🔍 What I Learned
- What are LLMs
- History: from RNNs → LSTMs → Transformers → GPT
- Key concepts: tokens, context, pretraining, inference

## 💡 Highlights
- LLMs process language by converting it to tokens
- Pretraining is done on massive corpora to learn patterns

## 🛠️ Tools Explored
- Google Colab
- HuggingFace Docs