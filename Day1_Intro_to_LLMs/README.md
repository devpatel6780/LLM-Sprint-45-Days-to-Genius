# ğŸ“˜ Day 1: Introduction to LLMs

## ğŸ” What I Learned
- What are LLMs
- History: from RNNs â†’ LSTMs â†’ Transformers â†’ GPT
- Key concepts: tokens, context, pretraining, inference

## ğŸ’¡ Highlights
- LLMs process language by converting it to tokens
- Pretraining is done on massive corpora to learn patterns

## ğŸ› ï¸ Tools Explored
- Google Colab
- HuggingFace Docs

- ## ğŸ”— Notebook Link
[ğŸ”— Open Day 1 Notebook in Colab](https://colab.research.google.com/drive/1RShcj7NLH_uJMsx0GRqdrLHPWdVv70r9)
