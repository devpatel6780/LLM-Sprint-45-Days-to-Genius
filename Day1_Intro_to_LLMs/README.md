# 📘 Day 1: Introduction to LLMs

## 🔍 What I Learned
- What are LLMs
- History: from RNNs → LSTMs → Transformers → GPT
- Key concepts: tokens, context, pretraining, inference

## 💡 Highlights
- LLMs process language by converting it to tokens
- Pretraining is done on massive corpora to learn patterns

## 🛠️ Tools Explored
- Google Colab
- HuggingFace Docs

- ## 🔗 Notebook Link
[🔗 Open Day 1 Notebook in Colab](https://colab.research.google.com/drive/1RShcj7NLH_uJMsx0GRqdrLHPWdVv70r9)
